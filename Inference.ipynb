{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0233a529-c0c5-41ff-995c-f681651abc60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Python3 Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c06f1d-e5f2-4acc-a879-a026ab30e9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"deploy\")\n",
    "os.mkdir(\"deploy/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ae8515-ef61-4436-acb2-543192c648a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cvproject2025/fine_tuned_model.zip...\n",
      "/ [1 files][ 18.9 MiB/ 18.9 MiB]                                                \n",
      "Operation completed over 1 objects/18.9 MiB.                                     \n",
      "Copying gs://cvproject2025/label_map.pbtxt...\n",
      "/ [1/1 files][   60.0 B/   60.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/60.0 B.                                       \n",
      "Copying gs://cvproject2025/dist/centroidtracker.py...\n",
      "/ [1/1 files][  5.8 KiB/  5.8 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/5.8 KiB.                                      \n",
      "Copying gs://cvproject2025/dist/trackableobject.py...\n",
      "/ [1/1 files][  328.0 B/  328.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/328.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "# Subir archivos de configuraciÃ³n\n",
    "!gsutil cp gs://cvproject2025/fine_tuned_model.zip deploy/model/fine_tuned_model.zip\n",
    "!gsutil -m cp gs://cvproject2025/label_map.pbtxt deploy/model/label_map.pbtxt\n",
    "\n",
    "!gsutil -m cp gs://cvproject2025/dist/centroidtracker.py deploy/centroidtracker.py\n",
    "!gsutil -m cp gs://cvproject2025/dist/trackableobject.py deploy/trackableobject.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd250d8-1d97-41aa-9ddf-50685dca79b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Descomprimimos \n",
    "import zipfile\n",
    "\n",
    "local_zip = \"deploy/model/fine_tuned_model.zip\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
    "zip_ref.extractall(\"deploy/model/fine_tuned_model\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede53800-7340-4365-bee7-ff45103418b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deploy/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy/app.py\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from prediction import smartcities\n",
    "import base64\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods = ['POST'])\n",
    "def parse_request():\n",
    "    request_data = request.get_json()\n",
    "    videoBase64 = request_data['video']\n",
    "    sc = smartcities()\n",
    "    response_64 = sc.predict(videoBase64)\n",
    "    return jsonify(output=response_64)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, host='0.0.0.0', port= 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7adb50b-f884-406a-aaa9-9bd7248b2554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deploy/prediction.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy/prediction.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "from centroidtracker import CentroidTracker\n",
    "from trackableobject import TrackableObject\n",
    "import base64\n",
    "\n",
    "class smartcities:\n",
    "    def __init__(self):\n",
    "        detect_fn = tf.saved_model.load(\"model/fine_tuned_model/content/fine_tuned_model/saved_model\")\n",
    "        self.detect_fn = detect_fn\n",
    "    \n",
    "    def predict(self, image_64_decode):\n",
    "        \n",
    "        PATH_VIDEO = \"/tmp/video_in.mp4\"\n",
    "        video_result = open(PATH_VIDEO, \"wb\")\n",
    "        video_result.write(base64.b64decode(image_64_decode))\n",
    "        \n",
    "        \n",
    "\n",
    "        PATH_OUTPUT = \"/tmp/output.mp4\"\n",
    "\n",
    "        SKIP_FPS = 30\n",
    "        TRESHOLD = 0.5\n",
    "\n",
    "        vs = cv2.VideoCapture(PATH_VIDEO)\n",
    "\n",
    "        writer = None\n",
    "\n",
    "        W = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        H = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        ct = CentroidTracker(maxDisappeared= 40, maxDistance = 50)\n",
    "\n",
    "        trackers = []\n",
    "        trackableObjects = {}\n",
    "\n",
    "        totalFrame = 0\n",
    "        totalDown = 0\n",
    "        totalUp = 0\n",
    "\n",
    "        DIRECTION_PEOPLE = True\n",
    "\n",
    "        POINT = [0, int((H/2)-H*0.1), W, int(H*0.1)]\n",
    "\n",
    "        fps = FPS().start()\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "        writer = cv2.VideoWriter(PATH_OUTPUT, fourcc, 20.0, (W, H), True)\n",
    "\n",
    "        while True:\n",
    "            ret, frame = vs.read()\n",
    "\n",
    "            if frame is None:\n",
    "                break\n",
    "\n",
    "            status = \"Waiting\"\n",
    "            rects = []\n",
    "\n",
    "\n",
    "            if totalFrame % SKIP_FPS == 0:\n",
    "                status = \"Detecting\"\n",
    "                trackers = []\n",
    "\n",
    "                image_np = np.array(frame)\n",
    "\n",
    "                input_tensor = tf.convert_to_tensor(image_np)\n",
    "                input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "                detections = self.detect_fn(input_tensor)\n",
    "\n",
    "                detection_scores = np.array(detections[\"detection_scores\"][0])\n",
    "\n",
    "                detection_clean = [x for x in detection_scores if x >= TRESHOLD]\n",
    "\n",
    "                for x in range(len(detection_clean)):\n",
    "                    idx = int(detections['detection_classes'][0][x])\n",
    "\n",
    "                    ymin, xmin, ymax, xmax = np.array(detections['detection_boxes'][0][x])\n",
    "                    box = [xmin, ymin, xmax, ymax] * np.array([W,H, W, H])\n",
    "\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                    tracker = dlib.correlation_tracker()\n",
    "                    rect = dlib.rectangle(startX, startY, endX, endY)\n",
    "                    tracker.start_track(frame, rect)\n",
    "\n",
    "                    trackers.append(tracker)\n",
    "            else:\n",
    "                for tracker in trackers:\n",
    "\n",
    "                    status = \"Tracking\"\n",
    "\n",
    "                    tracker.update(frame)\n",
    "                    pos = tracker.get_position()\n",
    "\n",
    "                    startX = int(pos.left())\n",
    "                    startY = int(pos.top())\n",
    "                    endX = int(pos.right())\n",
    "                    endY = int(pos.bottom())\n",
    "\n",
    "                    rects.append((startX, startY, endX, endY))\n",
    "\n",
    "            cv2.rectangle(frame, (POINT[0], POINT[1]), (POINT[0]+ POINT[2], POINT[1] + POINT[3]), (255, 0, 255), 2)\n",
    "\n",
    "            objects = ct.update(rects)\n",
    "\n",
    "            for (objectID, centroid) in objects.items():\n",
    "                to = trackableObjects.get(objectID, None)\n",
    "                if to is None:\n",
    "                    to = TrackableObject(objectID, centroid)\n",
    "\n",
    "                else:\n",
    "                    y = [c[1] for c in to.centroids]\n",
    "                    direction = centroid[1] - np.mean(y)\n",
    "                    to.centroids.append(centroid)\n",
    "\n",
    "                    if not to.counted:\n",
    "                        if centroid[0] > POINT[0] and centroid[0] < (POINT[0]+ POINT[2]) and centroid[1] > POINT[1] and centroid[1] < (POINT[1]+POINT[3]):\n",
    "                            if DIRECTION_PEOPLE:\n",
    "                                if direction >0:\n",
    "                                    totalUp += 1\n",
    "                                    to.counted = True\n",
    "                                else:\n",
    "                                    totalDown +=1\n",
    "                                    to.counted = True\n",
    "                            else:\n",
    "                                if direction <0:\n",
    "                                    totalUp += 1\n",
    "                                    to.counted = True\n",
    "                                else:\n",
    "                                    totalDown +=1\n",
    "                                    to.counted = True\n",
    "\n",
    "                trackableObjects[objectID] = to\n",
    "\n",
    "                text = \"ID {}\".format(objectID)\n",
    "                cv2.putText(frame, text, (centroid[0]-10, centroid[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "                cv2.circle(frame, (centroid[0], centroid[1]), 4, (0,255,0), -1)\n",
    "\n",
    "            info = [\n",
    "                  (\"Subiendo\", totalUp),\n",
    "                  (\"Bajando\", totalDown),\n",
    "                  (\"Estado\", status),\n",
    "            ]\n",
    "\n",
    "            for (i, (k,v)) in enumerate(info):\n",
    "                text = \"{}: {}\".format(k,v)\n",
    "                cv2.putText(frame, text, (10, H - ((i*20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
    "\n",
    "            writer.write(frame)\n",
    "\n",
    "            totalFrame += 1\n",
    "            fps.update()\n",
    "\n",
    "        fps.stop()\n",
    "\n",
    "        print(\"Tiempo completo {}\".format(fps.elapsed()))\n",
    "        print(\"Tiempo aproximado por frame {}\".format(fps.fps()))\n",
    "\n",
    "        writer.release()\n",
    "\n",
    "        vs.release()\n",
    "        \n",
    "        video = open(PATH_OUTPUT, \"rb\")\n",
    "        video_read = video.read()\n",
    "        image_64_encode = base64.b64encode(video_read)\n",
    "        image_64_encode_return = image_64_encode.decode() \n",
    "        return image_64_encode_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71957076-388f-479d-8a7d-726ae87664f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deploy/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy/requirements.txt\n",
    "tf_slim\n",
    "tf-models-official\n",
    "lvis\n",
    "Cython \n",
    "contextlib2 \n",
    "pillow \n",
    "lxml \n",
    "matplotlib\n",
    "pycocotools\n",
    "flask\n",
    "imutils\n",
    "numpy\n",
    "dlib\n",
    "opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91892a2d-768e-4404-8fbe-7f55761a15a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deploy/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy/Dockerfile\n",
    "\n",
    "FROM python:3.7\n",
    "COPY . /app\n",
    "RUN apt-get update && yes | apt-get upgrade\n",
    "WORKDIR /app\n",
    "RUN mkdir -p /tensorflow/models\n",
    "RUN apt-get install -y git python3-pip\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install tensorflow\n",
    "RUN apt-get install -y protobuf-compiler python3-pil python3-lxml\n",
    "RUN pip install matplotlib\n",
    "RUN git clone https://github.com/tensorflow/models.git /tensorflow/models\n",
    "RUN apt-get update && apt-get install -y cmake\n",
    "RUN apt-get install ffmpeg libsm6 libxext6  -y\n",
    "\n",
    "WORKDIR /tensorflow/models/research\n",
    "RUN protoc object_detection/protos/*.proto --python_out=.\n",
    "RUN export PYTHONPATH=$PYTHONPATH:pwd:pwd/slim\n",
    "\n",
    "WORKDIR /app\n",
    "RUN pip install -r requirements.txt\n",
    "CMD [\"python3\", \"./app.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e67cc8-7440-4fa5-9482-6c812fa7fd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
